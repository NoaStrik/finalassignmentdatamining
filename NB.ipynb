{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7986290263138498\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88     10241\n",
      "           1       0.68      0.33      0.45      3326\n",
      "\n",
      "    accuracy                           0.80     13567\n",
      "   macro avg       0.75      0.64      0.66     13567\n",
      "weighted avg       0.78      0.80      0.77     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                       'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "X = data.drop('income', axis=1) \n",
    "y = data['income'] \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_output = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Rowan) I asked ChatGPT for a basic Naive Bayes model and it provided me with this code. We (Noa and I) noticed that our CSV file had some missing information which in the file were noted as '?', I asked ChatGPT to remove these question marks in order to make te model more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Rowan) I noticed that this model is much better at predicting class 0 than class 1, therefore I will ask ChatGPT to improve the class 1 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 0.8037148964398909\n",
      "Adjusted Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88     10241\n",
      "           1       0.68      0.37      0.48      3326\n",
      "\n",
      "    accuracy                           0.80     13567\n",
      "   macro avg       0.75      0.66      0.68     13567\n",
      "weighted avg       0.79      0.80      0.78     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_prob = nb.predict_proba(X_test) \n",
    "\n",
    "threshold = 0.4 \n",
    "y_pred_adjusted = np.where(y_prob[:, 1] > threshold, 1, 0) \n",
    "\n",
    "accuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\n",
    "classification_report_adjusted = classification_report(y_test, y_pred_adjusted)\n",
    "\n",
    "print(f\"Adjusted Accuracy: {accuracy_adjusted}\")\n",
    "print(\"Adjusted Classification Report:\")\n",
    "print(classification_report_adjusted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Rowan) I asked ChatGPT to try and improve the precision of the prediction for class 1. After doing that I saw that the overall accuracy was higher after trying to improve the class 1 prediction, it went from 79% to 80%. \n",
    "Comparing the predictions between the classes shows that after the change the precision of class 0 went down by 1% while the recall was higher by 1%, the f1-score did not change.\n",
    "For class 1 the prediction stayed the same while the recall was higher by 4% and the f1-score was higher by 3%.\n",
    "\n",
    "Precision means that when the model predicted both of the classes it was correct x% of the time. For class 0 this was 82% while it for class 1 68% was.\n",
    "Recall means that the model correctly identified x% of the actual class 0/1 instances. For class 0, 94% and for class 1, 37%.\n",
    "f1-score indicates a balance between the precision and recall. for class 0 this was 88%, and for class 1 this was 48%.\n",
    "\n",
    "Looking at these results I conclude that the model is much better at predicting class 0 than class 1 since precision, recall and f1-score are higher than for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Rowan) discussion:\n",
    "\n",
    "The model predicts class 0 better than class 1. This is because of class imbalance. The reason for this imbalance is that in our dataset the majority of people earn less than 50K instead of more than 50K. Therefore the model is much better at predicting class 0 while it has more data to train and test on.\n",
    "\n",
    "To try and improve the class 1 prediction I will ask ChatGPT for an improvement of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More Adjusted Accuracy: 0.8142551780054544\n",
      "More Adjusted Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88     10241\n",
      "           1       0.66      0.49      0.57      3326\n",
      "\n",
      "    accuracy                           0.81     13567\n",
      "   macro avg       0.76      0.71      0.72     13567\n",
      "weighted avg       0.80      0.81      0.80     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.2 \n",
    "y_pred_more_adjusted = np.where(y_prob[:, 1] > threshold, 1, 0) \n",
    "\n",
    "accuracy_more_adjusted = accuracy_score(y_test, y_pred_more_adjusted)\n",
    "classification_report_more_adjusted = classification_report(y_test, y_pred_more_adjusted)\n",
    "\n",
    "print(f\"More Adjusted Accuracy: {accuracy_more_adjusted}\")\n",
    "print(\"More Adjusted Classification Report:\")\n",
    "print(classification_report_more_adjusted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Rowan) After asking ChatGPT to try and improve the model again, specifically for improving the predictions of class 1 the results above came out.\n",
    "\n",
    "Looking at these results and comparing them to the earlier results I saw that even though I asked the AI to improve class 1, class 0 also was improved.\n",
    "The precision for class 0 was increased from 82% to 85%, the recall decreased from 94% to 92% and the f1-score stayed the same. \n",
    "For class 1 the precision decreased from 68% to 66% while the recall improved from 37% to 49% and the f1-score increased from 48% to 57%.\n",
    "The overal prediction accuracy was also increased from 80% to 81%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practical examples for why it could be interesting for someone to predict someone else’s income are: \n",
    "1. Credit scoring and lending. Banks can use income predictions to determine if they are willing to lend someone money, to determine credit limits and terms.\n",
    "2. Targeted marketing. Being able to predict someone’s income could be interesting for companies so they can target to whom they will advertise.\n",
    "3. Insurances. Having the ability to predict someone's income could be handy for assessing risks and setting premiums.\n",
    "4. Real estate. Being able to predict income could be an advantage for evaluating mortgage approvals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVIEW\n",
    "\n",
    "(Noa) After looking at the models made and the improvements tried, I can conclude that Rowan did a fine job. What the model means is well explained and a discussion has been applied. The only thing that I am missing is more information on the steps that he has taken and more information about what he did to improve the model.\n",
    "\n",
    "Compared to my own model, the kNN model, Rowan his NB model is more accurate in class 0 and mine is more accurate in class 1. The overall accuracy is better with the NB model.\n",
    "\n",
    "Possible further improvements are assigning higher weights to class 1 in order to make the model more sensitive to misclassifications in class 1. Another improvement could be using SMOTE to oversample the underpresented class, which is in this case class 1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
